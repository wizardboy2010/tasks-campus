{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# MNIST Dataset \n",
    "mnist = dsets.MNIST(root='./data', \n",
    "                      train=True, \n",
    "                      transform=transforms.ToTensor(),  \n",
    "                      download=True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  ################# uses gpu if available\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aae_encoder(nn.Module):\n",
    "    def __init__(self, X_dim, N, latent_dim):\n",
    "        super(aae_encoder, self).__init__()\n",
    "        self.input_size = X_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.layer1 = nn.Linear(X_dim, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        \n",
    "        ######## mean and variance for gauss distribution\n",
    "        self.mean = nn.Linear(N, latent_dim)\n",
    "        self.variance = nn.Linear(N, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.2)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = F.dropout(self.layer2(x), p=0.2)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        ####### gaussion distribution\n",
    "        mean_layer = self.mean(x)\n",
    "        variance_layer = self.variance(x)\n",
    "        gauss_layer = Normal(torch.tensor(mean_layer), torch.tensor(variance_layer))\n",
    "        xgauss = gauss_layer.sample()+mean_layer\n",
    "        \n",
    "        return xgauss\n",
    "    \n",
    "class aae_decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, N, X_dim):\n",
    "        super(aae_decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_size = X_dim\n",
    "        \n",
    "        self.layer1 = nn.Linear(latent_dim, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, X_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.2)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = F.dropout(self.layer2(x), p=0.2)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "class aae_discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, N):\n",
    "        super(aae_discriminator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(latent_dim, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.2)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = F.dropout(self.layer2(x), p=0.2)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, discriminator):\n",
    "        super(AAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoder_output = self.encoder(x)\n",
    "        decoder_output = self.decoder(encoder_output)\n",
    "        discriminator_output = self.discriminator(encoder_output)\n",
    "        \n",
    "        return decoder_output, discriminator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "N = 512\n",
    "latent_dim = 128\n",
    "encoder = aae_encoder(784, N, latent_dim)\n",
    "decoder = aae_decoder(latent_dim, N, 784)\n",
    "discriminator = aae_discriminator(latent_dim, 64)\n",
    "\n",
    "aae = AAE(encoder, decoder, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning rates\n",
    "gen_lr = 0.0001\n",
    "reg_lr = 0.00005\n",
    "\n",
    "#encode/decode optimizers\n",
    "encoder_optim = torch.optim.Adam(encoder.parameters(), lr=gen_lr)\n",
    "decoder_optim = torch.optim.Adam(decoder.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "encoder_gen_optim = torch.optim.Adam(decoder.parameters(), lr=reg_lr)\n",
    "discriminator_optim = torch.optim.Adam(discriminator.parameters(), lr=reg_lr)\n",
    "\n",
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Step: 10 recon_loss: 0.6809074282646179 \tdiscriminator_loss: 1.5029983520507812 \tgenerator_loss: 0.6650325059890747\n",
      "For Step: 20 recon_loss: 0.6065708994865417 \tdiscriminator_loss: 1.4838974475860596 \tgenerator_loss: 0.665739119052887\n",
      "For Step: 30 recon_loss: 0.3767111301422119 \tdiscriminator_loss: 1.4573198556900024 \tgenerator_loss: 0.6902081370353699\n",
      "For Step: 40 recon_loss: 0.2907136082649231 \tdiscriminator_loss: 1.4237043857574463 \tgenerator_loss: 0.7225086092948914\n",
      "For Step: 50 recon_loss: 0.2934366762638092 \tdiscriminator_loss: 1.3274537324905396 \tgenerator_loss: 0.7617560625076294\n",
      "For Step: 60 recon_loss: 0.28590139746665955 \tdiscriminator_loss: 1.234162449836731 \tgenerator_loss: 0.7803312540054321\n",
      "For Step: 70 recon_loss: 0.28752437233924866 \tdiscriminator_loss: 1.2213034629821777 \tgenerator_loss: 0.8098970651626587\n",
      "For Step: 80 recon_loss: 0.26922914385795593 \tdiscriminator_loss: 1.1803001165390015 \tgenerator_loss: 0.8167733550071716\n",
      "For Step: 90 recon_loss: 0.2761061489582062 \tdiscriminator_loss: 1.1333407163619995 \tgenerator_loss: 0.8482468724250793\n",
      "For Step: 100 recon_loss: 0.27663034200668335 \tdiscriminator_loss: 1.110079288482666 \tgenerator_loss: 0.8575113415718079\n",
      "For Step: 110 recon_loss: 0.27563366293907166 \tdiscriminator_loss: 1.083928108215332 \tgenerator_loss: 0.8854902982711792\n",
      "For Step: 120 recon_loss: 0.26196402311325073 \tdiscriminator_loss: 1.0867518186569214 \tgenerator_loss: 0.8806390166282654\n",
      "For Step: 130 recon_loss: 0.26958978176116943 \tdiscriminator_loss: 1.0575058460235596 \tgenerator_loss: 0.9091143012046814\n",
      "For Step: 140 recon_loss: 0.2729865312576294 \tdiscriminator_loss: 1.0236196517944336 \tgenerator_loss: 0.9069353938102722\n",
      "For Step: 150 recon_loss: 0.274785578250885 \tdiscriminator_loss: 1.0118659734725952 \tgenerator_loss: 0.9270569086074829\n",
      "For Step: 160 recon_loss: 0.26397326588630676 \tdiscriminator_loss: 0.9478669166564941 \tgenerator_loss: 0.9355764389038086\n",
      "For Step: 170 recon_loss: 0.26902809739112854 \tdiscriminator_loss: 0.967881441116333 \tgenerator_loss: 0.9831262230873108\n",
      "For Step: 180 recon_loss: 0.27769410610198975 \tdiscriminator_loss: 0.9411479234695435 \tgenerator_loss: 0.9281689524650574\n",
      "For Step: 190 recon_loss: 0.26737475395202637 \tdiscriminator_loss: 0.8778456449508667 \tgenerator_loss: 0.9828667640686035\n",
      "For Step: 200 recon_loss: 0.25037693977355957 \tdiscriminator_loss: 0.8790781497955322 \tgenerator_loss: 1.022594690322876\n",
      "For Step: 210 recon_loss: 0.25790587067604065 \tdiscriminator_loss: 0.844656229019165 \tgenerator_loss: 1.042499303817749\n",
      "For Step: 220 recon_loss: 0.26769113540649414 \tdiscriminator_loss: 0.8911344408988953 \tgenerator_loss: 1.0032532215118408\n",
      "For Step: 230 recon_loss: 0.2437489628791809 \tdiscriminator_loss: 0.8423934578895569 \tgenerator_loss: 1.0425547361373901\n",
      "For Step: 240 recon_loss: 0.25573188066482544 \tdiscriminator_loss: 0.8265644907951355 \tgenerator_loss: 1.0264917612075806\n",
      "For Step: 250 recon_loss: 0.25605764985084534 \tdiscriminator_loss: 0.7867862582206726 \tgenerator_loss: 1.0299770832061768\n",
      "For Step: 260 recon_loss: 0.2538891136646271 \tdiscriminator_loss: 0.7721819877624512 \tgenerator_loss: 1.049072265625\n",
      "For Step: 270 recon_loss: 0.2594468593597412 \tdiscriminator_loss: 0.7549583911895752 \tgenerator_loss: 1.0797839164733887\n",
      "For Step: 280 recon_loss: 0.24724508821964264 \tdiscriminator_loss: 0.7439254522323608 \tgenerator_loss: 1.082144021987915\n",
      "For Step: 290 recon_loss: 0.2530880272388458 \tdiscriminator_loss: 0.7054017782211304 \tgenerator_loss: 1.087172269821167\n",
      "For Step: 300 recon_loss: 0.2489771544933319 \tdiscriminator_loss: 0.6764366626739502 \tgenerator_loss: 1.103795051574707\n",
      "For Step: 310 recon_loss: 0.24830342829227448 \tdiscriminator_loss: 0.6911200881004333 \tgenerator_loss: 1.093255639076233\n",
      "For Step: 320 recon_loss: 0.24071212112903595 \tdiscriminator_loss: 0.7123308181762695 \tgenerator_loss: 1.132411241531372\n",
      "For Step: 330 recon_loss: 0.24492810666561127 \tdiscriminator_loss: 0.6449589729309082 \tgenerator_loss: 1.1657049655914307\n",
      "For Step: 340 recon_loss: 0.23508985340595245 \tdiscriminator_loss: 0.7104821801185608 \tgenerator_loss: 1.2155416011810303\n",
      "For Step: 350 recon_loss: 0.2379271239042282 \tdiscriminator_loss: 0.711988091468811 \tgenerator_loss: 1.1538951396942139\n",
      "For Step: 360 recon_loss: 0.2355377972126007 \tdiscriminator_loss: 0.657249927520752 \tgenerator_loss: 1.2110533714294434\n",
      "For Step: 370 recon_loss: 0.23957780003547668 \tdiscriminator_loss: 0.5728436708450317 \tgenerator_loss: 1.2549196481704712\n",
      "For Step: 380 recon_loss: 0.23927706480026245 \tdiscriminator_loss: 0.5733561515808105 \tgenerator_loss: 1.2534672021865845\n",
      "For Step: 390 recon_loss: 0.22907359898090363 \tdiscriminator_loss: 0.5487576127052307 \tgenerator_loss: 1.300035834312439\n",
      "For Step: 400 recon_loss: 0.22840408980846405 \tdiscriminator_loss: 0.5991891026496887 \tgenerator_loss: 1.2797245979309082\n",
      "For Step: 410 recon_loss: 0.23061326146125793 \tdiscriminator_loss: 0.5931091904640198 \tgenerator_loss: 1.3484439849853516\n",
      "For Step: 420 recon_loss: 0.2353842556476593 \tdiscriminator_loss: 0.5592932105064392 \tgenerator_loss: 1.3053231239318848\n",
      "For Step: 430 recon_loss: 0.22934909164905548 \tdiscriminator_loss: 0.5010142922401428 \tgenerator_loss: 1.4238905906677246\n",
      "For Step: 440 recon_loss: 0.22012341022491455 \tdiscriminator_loss: 0.46154332160949707 \tgenerator_loss: 1.450851559638977\n",
      "For Step: 450 recon_loss: 0.21548323333263397 \tdiscriminator_loss: 0.4613504111766815 \tgenerator_loss: 1.531649112701416\n",
      "For Step: 460 recon_loss: 0.21936386823654175 \tdiscriminator_loss: 0.47285032272338867 \tgenerator_loss: 1.480018973350525\n",
      "For Step: 470 recon_loss: 0.2109631448984146 \tdiscriminator_loss: 0.431312620639801 \tgenerator_loss: 1.5752066373825073\n",
      "For Step: 480 recon_loss: 0.20096702873706818 \tdiscriminator_loss: 0.4612463414669037 \tgenerator_loss: 1.5931739807128906\n",
      "For Step: 490 recon_loss: 0.21077533066272736 \tdiscriminator_loss: 0.4444829821586609 \tgenerator_loss: 1.6135538816452026\n",
      "For Step: 500 recon_loss: 0.2060568630695343 \tdiscriminator_loss: 0.4378679692745209 \tgenerator_loss: 1.732907772064209\n",
      "For Step: 510 recon_loss: 0.19642220437526703 \tdiscriminator_loss: 0.42166072130203247 \tgenerator_loss: 1.7251129150390625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-06ef864df582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mrecon_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mdecoder_optim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mencoder_optim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# Discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "reconstruction_loss = []\n",
    "discriminator_loss = []\n",
    "generator_loss = []\n",
    "gen_learning_rate = []\n",
    "reg_learning_rate = []\n",
    "\n",
    "# z_real_gauss = Variable(torch.randn(batch_size, latent_dim) * 5.)\n",
    "\n",
    "for step in range(total_step):\n",
    "    \n",
    "    if (step+1)%1000:\n",
    "        gen_lr /= 5\n",
    "        reg_lr /= 5\n",
    "\n",
    "    gen_learning_rate.append(gen_lr)\n",
    "    reg_learning_rate.append(reg_lr)\n",
    "    \n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch the images and labels and convert them to variables\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = to_var(images.view(batch_size, -1)), to_var(labels)\n",
    "\n",
    "    #reconstruction loss\n",
    "    decoder.zero_grad()\n",
    "    encoder.zero_grad()\n",
    "    discriminator.zero_grad()\n",
    "\n",
    "    X_sample, pred = aae(images)\n",
    "    recon_loss = F.binary_cross_entropy(X_sample+EPS,images+EPS)\n",
    "\n",
    "    recon_loss.backward()\n",
    "    decoder_optim.step()\n",
    "    encoder_optim.step()\n",
    "\n",
    "    # Discriminator\n",
    "    ## true prior is random normal (randn)\n",
    "    ## this is constraining the Z-projection to be normal!\n",
    "    encoder.eval()\n",
    "#     z_real_gauss = Variable(torch.randn(images.size()[0], latent_dim) * 5.).cuda()\n",
    "#     z_real_gauss = Variable(torch.randn(batch_size, latent_dim) * 5., )\n",
    "    X_sample, pred = aae(images)\n",
    "    z_real_gauss = torch.randn(batch_size, latent_dim) * 5.\n",
    "    Disc_real_gauss = discriminator(z_real_gauss)\n",
    "\n",
    "    Disc_loss = -torch.mean(torch.log(Disc_real_gauss + EPS) + torch.log(1 - pred + EPS))\n",
    "\n",
    "    Disc_loss.backward(retain_graph=True)\n",
    "    discriminator_optim.step()\n",
    "\n",
    "    # Generator\n",
    "    encoder.train()\n",
    "    z_fake_gauss = encoder(images)\n",
    "    Disc_fake_gauss = discriminator(z_fake_gauss)\n",
    "    \n",
    "    Gen_loss = -torch.mean(torch.log(Disc_fake_gauss + EPS))\n",
    "\n",
    "    Gen_loss.backward()\n",
    "    encoder_gen_optim.step()   \n",
    "    \n",
    "    if (step+1) % 10 == 0:\n",
    "        print('For Step:', step+1 ,'recon_loss:', recon_loss.item(),\n",
    "        '\\tdiscriminator_loss:', Disc_loss.item(),\n",
    "        '\\tgenerator_loss:', Gen_loss.item())\n",
    "        reconstruction_loss.append(recon_loss.item())\n",
    "        discriminator_loss.append(Disc_loss.item())\n",
    "        generator_loss.append(Gen_loss.item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
