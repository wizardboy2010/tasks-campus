{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks....................... Generative\n",
    "\n",
    "Naive Bayes classifier................ Discriminative\n",
    "\n",
    "Logistic regression................... Generative\n",
    "\n",
    "Gaussian Mixture model................ Generative\n",
    "\n",
    "GANs.................................. Generative\n",
    "\n",
    "LDA(Latent Dirichlet Allocation)...... Generative\n",
    "\n",
    "SVM................................... Discriminative\n",
    "\n",
    "Decision Tree......................... Discriminative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank,brown\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = brown.tagged_sents(tagset='universal')[:-100]\n",
    "test_corpus = brown.tagged_sents(tagset='universal')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "pos_ord = []\n",
    "word_dict = {}\n",
    "for i in corpus:\n",
    "    pos_ord.append([j[1] for j in i])\n",
    "    for j in i:\n",
    "        if j[1] not in pos_dict:\n",
    "            pos_dict[j[1]] = [j[0].lower()]\n",
    "        else:\n",
    "            pos_dict[j[1]].append(j[0].lower())\n",
    "        if j[0].lower() not in word_dict:\n",
    "            word_dict[j[0].lower()] = [j[1]]\n",
    "        else:\n",
    "            word_dict[j[0].lower()].append(j[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_mat = {i:{j:0 for j in pos_dict} for i in pos_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in corpus:\n",
    "    for j in range(len(i)-1):\n",
    "        transition_mat[i[j][1]][i[j+1][1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_mat = {i:{j:transition_mat[i][j]/sum(transition_mat[i].values()) for j in pos_dict} for i in pos_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TM = np.array([list(i.values()) for i in transition_mat.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.91780902e-03,   6.26468480e-01,   2.39835852e-01,\n",
       "          6.47155209e-02,   9.09250508e-03,   1.27499890e-02,\n",
       "          1.75047182e-02,   6.43717174e-04,   2.01161617e-03,\n",
       "          9.89715155e-03,   9.76548213e-03,   1.39715887e-03],\n",
       "       [  1.55527916e-02,   1.49845165e-01,   1.29375590e-02,\n",
       "          1.59437999e-01,   2.45189905e-01,   2.84527817e-01,\n",
       "          2.64587125e-02,   5.98767886e-02,   1.78871693e-02,\n",
       "          1.98495056e-02,   8.10466766e-03,   3.31919333e-04],\n",
       "       [  5.85278276e-03,   6.53058049e-01,   5.69239976e-02,\n",
       "          1.74745661e-02,   8.84739677e-02,   1.00371035e-01,\n",
       "          9.64691801e-03,   3.76181927e-02,   1.92938360e-02,\n",
       "          3.80610413e-03,   6.98982645e-03,   4.90724117e-04],\n",
       "       [  1.63020222e-01,   9.76256048e-02,   5.75714019e-02,\n",
       "          1.84405139e-01,   1.69274405e-01,   8.06515323e-02,\n",
       "          1.03320203e-01,   1.43846213e-02,   6.56305204e-02,\n",
       "          5.49545200e-02,   8.98078759e-03,   1.81042144e-04],\n",
       "       [  4.55622080e-01,   2.58494549e-01,   8.26925074e-02,\n",
       "          4.12597335e-02,   2.02941685e-02,   9.74563073e-03,\n",
       "          1.54905693e-02,   1.88960028e-03,   1.42308358e-02,\n",
       "          6.96937186e-02,   3.01367019e-02,   4.49904828e-04],\n",
       "       [  1.09322220e-01,   1.33899978e-01,   4.66988375e-02,\n",
       "          1.23645536e-01,   1.05220443e-01,   1.73162974e-01,\n",
       "          7.03443738e-02,   1.11899539e-01,   2.96007896e-02,\n",
       "          7.46764641e-02,   1.94998903e-02,   2.02895372e-03],\n",
       "       [  7.36429272e-02,   3.28728051e-02,   1.36268830e-01,\n",
       "          2.40395757e-01,   1.42098226e-01,   1.70068634e-01,\n",
       "          9.69070327e-02,   1.73277476e-02,   2.86656565e-02,\n",
       "          4.83465550e-02,   1.33166949e-02,   8.91345040e-05],\n",
       "       [  1.51136214e-01,   2.43819782e-01,   1.12123998e-01,\n",
       "          1.95376330e-01,   7.33482201e-02,   2.07539735e-02,\n",
       "          9.13700250e-02,   2.62708525e-04,   2.50361224e-02,\n",
       "          6.75423617e-02,   1.86785761e-02,   5.51687902e-04],\n",
       "       [  8.36638655e-02,   3.57983193e-02,   1.89243697e-02,\n",
       "          6.22689076e-01,   9.06890756e-02,   7.66050420e-02,\n",
       "          3.61344538e-02,   1.22352941e-02,   1.12605042e-02,\n",
       "          6.82352941e-03,   5.10924370e-03,   6.72268908e-05],\n",
       "       [  1.75517094e-02,   8.88771380e-03,   9.51819236e-03,\n",
       "          7.06481726e-01,   5.55838028e-02,   1.03581525e-01,\n",
       "          5.40381134e-02,   1.14299660e-02,   2.37548049e-02,\n",
       "          8.19622120e-03,   9.76224857e-04,   0.00000000e+00],\n",
       "       [  1.31997563e-02,   3.82319096e-01,   5.95004400e-02,\n",
       "          4.57591552e-02,   1.31794490e-01,   2.72524200e-01,\n",
       "          2.05103906e-02,   3.85162120e-02,   5.27990252e-03,\n",
       "          8.52907331e-03,   2.18642117e-02,   2.03073174e-04],\n",
       "       [  5.12070227e-03,   5.48646672e-02,   2.92611558e-03,\n",
       "          5.26700805e-02,   5.34016094e-02,   2.73591807e-01,\n",
       "          6.58376006e-03,   2.26773958e-02,   7.31528895e-03,\n",
       "          6.58376006e-03,   7.31528895e-04,   5.13533285e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_pos = [i[0] for i in pos_ord]\n",
    "start_mat = {i:start_pos.count(i)/len(start_pos) for i in pos_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SM = np.array(list(start_mat.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21339972,  0.14129979,  0.03434661,  0.04509085,  0.12283368,\n",
       "        0.08901118,  0.0911775 ,  0.04916143,  0.03665269,  0.15971349,\n",
       "        0.01678896,  0.00052411])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emission Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emission_matrix = {i:{j:0 for j in word_dict} for i in pos_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in corpus:\n",
    "    for j in i:\n",
    "        emission_matrix[j[1]][j[0].lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emission_matrix = {i:{j:emission_matrix[i][j]/len(pos_dict[i]) for j in word_dict} for i in pos_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM = np.array([list(i.values()) for i in emission_matrix.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.10846669e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   6.18013269e-05,   5.59847314e-04, ...,\n",
       "          3.63537217e-06,   0.00000000e+00,   3.63537217e-06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   1.19644417e-05,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  2.19138057e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def viterbi(observations, pos_names = list(pos_dict.keys()), start_probability= start_mat, transition_probability = transition_mat, emission_probability= emission_matrix):\n",
    "    pos = [{}]\n",
    "    path = {}\n",
    "    \n",
    "    r = random.uniform(0,1e-06)\n",
    "    for i in observations:\n",
    "        for j in pos_names:\n",
    "            if i not in emission_matrix[j]:\n",
    "                emission_matrix[j][i] = r\n",
    "    \n",
    "    for state in pos_names:\n",
    "        pos[0][state] = start_probability[state] * emission_probability[state][observations[0]]\n",
    "        path[state] = [state]\n",
    "\n",
    "    for observations_index in range(1,len(observations)):\n",
    "        pos.append({})\n",
    "        new_path = {}\n",
    "        for state in pos_names:\n",
    "            (probability, possible_state) = max(\n",
    "            [(pos[observations_index-1][y0] * transition_probability[y0][state] \n",
    "            * emission_probability[state][observations[observations_index]], y0) for y0 in pos_names])\n",
    "\n",
    "            pos[observations_index][state] = probability\n",
    "            new_path[state] = path[possible_state] + [state]\n",
    "\n",
    "        path = new_path\n",
    "\n",
    "    (probability, state) = max([(pos[len(observations) - 1][state], state) for state in pos_names])\n",
    "    return probability, path[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accu(a, b):\n",
    "    return sum(1 for x,y in zip(a,b) if x == y) / len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following corpus:\n",
      "\n",
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "DET NOUN NOUN ADJ NOUN VERB NOUN DET NOUN ADP NOUN ADJ NOUN NOUN VERB . DET NOUN . ADP DET NOUN VERB NOUN . -True\n",
      "DET NOUN ADP DET NOUN ADP DET NOUN ADP DET NOUN ADP DET NOUN ADP DET NOUN ADP DET NOUN ADP DET NOUN ADP DET -predicted\n"
     ]
    }
   ],
   "source": [
    "print('For the following corpus:\\n')\n",
    "print(' '.join([i[0] for i in corpus[0]]))\n",
    "print(' '.join([i[1] for i in corpus[0]]),'-True')\n",
    "print(' '.join(viterbi([i[0].lower for i in corpus[0]])[1]),'-predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On Test Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923871132215036"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([accu([j[1] for j in i], viterbi([j[0].lower() for j in i])[1]) for i in test_corpus])/len(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features ={\n",
    "    'bias': 1.0,\n",
    "    }\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in corpus]\n",
    "y_train=[sent2labels(s) for s in corpus]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_corpus]\n",
    "y_test=[sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12985271687027178"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      0.800     0.242     0.372        33\n",
      "          X      0.023     1.000     0.044         3\n",
      "        ADJ      0.000     0.000     0.000        18\n",
      "        ADP      0.179     0.185     0.182        27\n",
      "        ADV      0.000     0.000     0.000         9\n",
      "       VERB      0.000     0.000     0.000        35\n",
      "        DET      0.121     0.121     0.121        33\n",
      "       CONJ      0.000     0.000     0.000         7\n",
      "       NOUN      0.242     0.157     0.190        51\n",
      "       PRON      0.000     0.000     0.000        12\n",
      "        PRT      0.000     0.000     0.000        11\n",
      "        NUM      0.000     0.000     0.000         0\n",
      "\n",
      "avg / total      0.199     0.117     0.130       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
