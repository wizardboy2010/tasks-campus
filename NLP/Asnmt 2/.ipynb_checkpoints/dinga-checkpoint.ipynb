{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labeling in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the transition, start and emission matrix . The states stand for high and low.  The HMM model is given in the assignment itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "P= np.array([[0.6, 0.4],[0.5,0.5]])\n",
    "\n",
    "S= np.array([0.5, 0.5])\n",
    "\n",
    "O= np.array([[0.3,0.2,0.2,0.3],[0.2,0.3,0.3,0.2]])\n",
    "\n",
    "state={}\n",
    "state[0]='L'\n",
    "state[1]='H'\n",
    "\n",
    "DNA={}\n",
    "DNA['A']=0\n",
    "DNA['C']=1\n",
    "DNA['G']=2\n",
    "DNA['T']=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A stupid attempt to show you why the exhaustive search is a bad, bad option for HMM modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import time \n",
    "def exhaustive_search(sequence):\n",
    "    \n",
    "    M= len(sequence)\n",
    "    state_len= len(S)\n",
    "    \n",
    "    # track the best sequence and its score\n",
    "    best=(None,float('-inf'))\n",
    "    \n",
    "    # basically loop will run for |states|^M \n",
    "    for ss in product(range(state_len),repeat=M):\n",
    "        \n",
    "        score= S[ss[0]]*O[ss[0],DNA[sequence[0]]]\n",
    "        \n",
    "        for i in range(1,M):\n",
    "            score*= P[ss[i-1],ss[i]]*O[ss[i],DNA[sequence[i]]]\n",
    "            \n",
    "        \n",
    "        #print(','.join([state[k] for k in ss]),score)\n",
    "    \n",
    "        if score > best[1]:\n",
    "            best= (ss,score)\n",
    "    \n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sequence GGC of length 3 time taken was 0.0s\n",
      "The sequence H,H,H gave the best score of 0.003375\n",
      "\n",
      "\n",
      "For the sequence GGCAAGATCAT of length 11 time taken was 0.032s\n",
      "The sequence H,H,H,L,L,L,L,L,L,L,L gave the best score of 1.377495072e-09\n",
      "\n",
      "\n",
      "For the sequence GAGAGGAGAGAGAGAGAGA of length 19 time taken was 10.182s\n",
      "The sequence H,L,L,L,H,H,L,L,L,L,L,L,L,L,L,L,L,L,L gave the best score of 1.3326697514e-16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequences=['GGC','GGCAAGATCAT','GAGAGGAGAGAGAGAGAGA']\n",
    "\n",
    "import time\n",
    "for sequence in sequences:\n",
    "    \n",
    "    t=time.time()\n",
    "    best=exhaustive_search(sequence)\n",
    "    t2=time.time()-t\n",
    "    \n",
    "    print('For the sequence '+ sequence+ ' of length '+ str(len(sequence))+' time taken was '+ str(round(t2,3))+'s' )\n",
    "    print('The sequence '+ ','.join([state[k] for k in best[0]])+ ' gave the best score of '+ str(best[1]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assignment part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for this assignment: Brown corpus tagged with the Universal Tagset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will be your training set. The remaining 100 sentences will be used as your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55907\n",
      "12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank,brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "tags = []\n",
    "words = []\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag= elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "            words.append(w)\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "            tags.append(tag)\n",
    "\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1\n",
    "\n",
    "print(len(word_dict))\n",
    "print(len(tag_dict))\n",
    "        \n",
    "test_data= brown.tagged_sents(tagset='universal')[-10:]\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the transition, start and emission matrices from the training data.\n",
    "trans = {}\n",
    "start = {}\n",
    "emmis = {}\n",
    "for tag in tags:\n",
    "    trans[tag] = {}\n",
    "    start[tag] = 0\n",
    "    emmis[tag] = {}\n",
    "    for item in tags:\n",
    "        trans[tag][item] = 0\n",
    "    for w in words:\n",
    "        emmis[tag][w] = 0\n",
    "for sent in corpus:\n",
    "    start[sent[0][1]]+=1;\n",
    "    for elem in range(0, len(sent)-1):\n",
    "        u = sent[elem][1]\n",
    "        v = sent[elem+1][1]\n",
    "        o1 = sent[elem][0]\n",
    "        trans[u][v]+=1;\n",
    "        emmis[u][o1]+=1;\n",
    "    u = sent[len(sent)-1][1]\n",
    "    o1 = sent[len(sent)-1][0]\n",
    "    emmis[u][o1]+=1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.91780902e-03   6.26468480e-01   2.39835852e-01   6.47155209e-02\n",
      "    9.09250508e-03   1.27499890e-02   1.75047182e-02   6.43717174e-04\n",
      "    2.01161617e-03   9.89715155e-03   9.76548213e-03   1.39715887e-03]\n",
      " [  1.55527916e-02   1.49845165e-01   1.29375590e-02   1.59437999e-01\n",
      "    2.45189905e-01   2.84527817e-01   2.64587125e-02   5.98767886e-02\n",
      "    1.78871693e-02   1.98495056e-02   8.10466766e-03   3.31919333e-04]\n",
      " [  5.85278276e-03   6.53058049e-01   5.69239976e-02   1.74745661e-02\n",
      "    8.84739677e-02   1.00371035e-01   9.64691801e-03   3.76181927e-02\n",
      "    1.92938360e-02   3.80610413e-03   6.98982645e-03   4.90724117e-04]\n",
      " [  1.63020222e-01   9.76256048e-02   5.75714019e-02   1.84405139e-01\n",
      "    1.69274405e-01   8.06515323e-02   1.03320203e-01   1.43846213e-02\n",
      "    6.56305204e-02   5.49545200e-02   8.98078759e-03   1.81042144e-04]\n",
      " [  4.55622080e-01   2.58494549e-01   8.26925074e-02   4.12597335e-02\n",
      "    2.02941685e-02   9.74563073e-03   1.54905693e-02   1.88960028e-03\n",
      "    1.42308358e-02   6.96937186e-02   3.01367019e-02   4.49904828e-04]\n",
      " [  1.09322220e-01   1.33899978e-01   4.66988375e-02   1.23645536e-01\n",
      "    1.05220443e-01   1.73162974e-01   7.03443738e-02   1.11899539e-01\n",
      "    2.96007896e-02   7.46764641e-02   1.94998903e-02   2.02895372e-03]\n",
      " [  7.36429272e-02   3.28728051e-02   1.36268830e-01   2.40395757e-01\n",
      "    1.42098226e-01   1.70068634e-01   9.69070327e-02   1.73277476e-02\n",
      "    2.86656565e-02   4.83465550e-02   1.33166949e-02   8.91345040e-05]\n",
      " [  1.51136214e-01   2.43819782e-01   1.12123998e-01   1.95376330e-01\n",
      "    7.33482201e-02   2.07539735e-02   9.13700250e-02   2.62708525e-04\n",
      "    2.50361224e-02   6.75423617e-02   1.86785761e-02   5.51687902e-04]\n",
      " [  8.36638655e-02   3.57983193e-02   1.89243697e-02   6.22689076e-01\n",
      "    9.06890756e-02   7.66050420e-02   3.61344538e-02   1.22352941e-02\n",
      "    1.12605042e-02   6.82352941e-03   5.10924370e-03   6.72268908e-05]\n",
      " [  1.75517094e-02   8.88771380e-03   9.51819236e-03   7.06481726e-01\n",
      "    5.55838028e-02   1.03581525e-01   5.40381134e-02   1.14299660e-02\n",
      "    2.37548049e-02   8.19622120e-03   9.76224857e-04   0.00000000e+00]\n",
      " [  1.31997563e-02   3.82319096e-01   5.95004400e-02   4.57591552e-02\n",
      "    1.31794490e-01   2.72524200e-01   2.05103906e-02   3.85162120e-02\n",
      "    5.27990252e-03   8.52907331e-03   2.18642117e-02   2.03073174e-04]\n",
      " [  5.12070227e-03   5.48646672e-02   2.92611558e-03   5.26700805e-02\n",
      "    5.34016094e-02   2.73591807e-01   6.58376006e-03   2.26773958e-02\n",
      "    7.31528895e-03   6.58376006e-03   7.31528895e-04   5.13533285e-01]]\n",
      "[ 0.21339972  0.14129979  0.03434661  0.04509085  0.12283368  0.08901118\n",
      "  0.0911775   0.04916143  0.03665269  0.15971349  0.01678896  0.00052411]\n",
      "[[  5.30045932e-02   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   6.18013269e-05   3.05371262e-04 ...,   0.00000000e+00\n",
      "    3.63537217e-06   3.63537217e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   1.19644417e-05\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Caluclating Probabilities\n",
    "sum = 0\n",
    "for tag in tags:\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    sum += start[tag]\n",
    "    for item in tags:\n",
    "        sum1 += trans[tag][item]\n",
    "    for item in tags:\n",
    "        trans[tag][item] /= sum1\n",
    "    for w in words:\n",
    "        sum2 += emmis[tag][w]\n",
    "    for w in words:\n",
    "        emmis[tag][w] /= sum2\n",
    "for tag in tags:\n",
    "    start[tag] /= sum\n",
    "\n",
    "P1 = np.zeros([len(tag_dict),len(tag_dict)])\n",
    "S1 = np.zeros(len(tag_dict))\n",
    "O1 = np.zeros([len(tag_dict),len(word_dict)])\n",
    "for i in range(0, len(tags)):\n",
    "    S1[i] = start[tags[i]]\n",
    "    for j in range(0, len(tags)):\n",
    "        P1[i][j] = trans[tags[i]][tags[j]]\n",
    "    for j in range(0, len(words)):\n",
    "        O1[i][j] = emmis[tags[i]][words[j]]\n",
    "# print(trans)\n",
    "# print(start)\n",
    "# print(emmis)\n",
    "print(P1)\n",
    "print(S1)\n",
    "print(O1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_accuracy:  0.8152447428371007\n"
     ]
    }
   ],
   "source": [
    "# Formulate the Viterbi algorithm on the given matrices\n",
    "# The matrics trans,emmis,start are given along with the set of words\n",
    "accuracy = 1;\n",
    "sent_no = 1;\n",
    "for sent in test_data:\n",
    "    n = len(sent)\n",
    "    v = np.zeros([n,len(tag_dict)])\n",
    "    bt = np.zeros([n,len(tag_dict)])\n",
    "    temp = np.zeros(n,dtype = int)\n",
    "    i = sent[0][0]\n",
    "    for j in range(0,len(tag_dict)):\n",
    "        if i in words:\n",
    "            v[0][j] = start[tags[j]]*emmis[tags[j]][i]\n",
    "            bt[0][j] = -1\n",
    "        else:\n",
    "            v[0][j] = start[tags[j]]*random.uniform(0,1e-06)\n",
    "            bt[0][j] = -1\n",
    "    for i in range(1,n):\n",
    "        item = sent[i][0]\n",
    "        for j in range(0, len(tags)):\n",
    "            if item in words:\n",
    "                for k in range(0, len(tags)):\n",
    "                        if(v[i][j]  < v[i-1][k]*trans[tags[k]][tags[j]]*emmis[tags[j]][item]):\n",
    "                            v[i][j]  = v[i-1][k]*trans[tags[k]][tags[j]]*emmis[tags[j]][item]\n",
    "                            bt[i][j] = k\n",
    "            else:\n",
    "                for k in range(0, len(tags)):\n",
    "                        r = random.uniform(0,1e-06)\n",
    "                        if(v[i][j]  < v[i-1][k]*trans[tags[k]][tags[j]]*r):\n",
    "                            v[i][j] = v[i-1][k]*trans[tags[k]][tags[j]]*r\n",
    "                            bt[i][j] = k\n",
    "    for j in range(0,len(tag_dict)):\n",
    "        if(temp[n-1] > v[n-1][j]):\n",
    "            temp[n-1] = j\n",
    "    for i in range(len(sent)-1,0,-1):\n",
    "        temp[i-1] = bt[i][temp[i]]\n",
    "    \n",
    "    ans = []\n",
    "    for i in temp:\n",
    "        ans.append(tags[i])\n",
    "    # Checking accuracy\n",
    "    count = 0\n",
    "    for i in range(0,n):\n",
    "        if(ans[i] == sent[i][1]):\n",
    "            count +=1\n",
    "    count/=n\n",
    "    if(count==0):\n",
    "        count = 1\n",
    "    accuracy = (accuracy*(sent_no-1)+count)/sent_no\n",
    "    sent_no+=1\n",
    "    \n",
    "print(\"overall_accuracy: \",accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module to implement CRF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn_crfsuite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8f727e9b15fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pip3 install sklearn-crfsuite # install this please\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn_crfsuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn_crfsuite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn_crfsuite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn_crfsuite'"
     ]
    }
   ],
   "source": [
    "# pip3 install sklearn-crfsuite # install this please\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "train_sents= corpus\n",
    "\n",
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features ={\n",
    "    'bias': 1.0,\n",
    "    }\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_data]\n",
    "y_test=[sent2labels(s) for s in test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
